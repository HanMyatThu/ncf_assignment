{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eiuOpyskxLEp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieLensDataset(Dataset):\n",
        "    def __init__(self, ratings, num_negatives=4, all_movies=None, user_item_set=None):\n",
        "        self.ratings = ratings\n",
        "        self.num_negatives = num_negatives\n",
        "        self.users = ratings['userId'].values\n",
        "        self.items = ratings['movie_idx'].values\n",
        "        self.labels = ratings['label'].values\n",
        "\n",
        "        self.all_movies = all_movies if all_movies is not None else set(ratings['movie_idx'].unique())\n",
        "        self.user_item_set = user_item_set if user_item_set is not None else set(zip(self.users, self.items))\n",
        "        self.num_users = max(ratings['userId'].max() + 1, ratings['userId'].nunique())\n",
        "        self.num_items = max(ratings['movie_idx'].max() + 1, ratings['movie_idx'].nunique())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings) * (self.num_negatives + 1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = idx // (self.num_negatives + 1)\n",
        "        user = self.users[real_idx]\n",
        "        item = self.items[real_idx]\n",
        "        label = self.labels[real_idx]\n",
        "\n",
        "        if idx % (self.num_negatives + 1) == 0: #+ve\n",
        "            return torch.LongTensor([user]), torch.LongTensor([item]), torch.FloatTensor([label])\n",
        "        else:\n",
        "            neg_item = self._negative_sampling(user) #-ve\n",
        "            return torch.LongTensor([user]), torch.LongTensor([neg_item]), torch.FloatTensor([0])\n",
        "\n",
        "    def _negative_sampling(self, user):\n",
        "        neg_item = np.random.choice(list(self.all_movies))\n",
        "        while (user, neg_item) in self.user_item_set:\n",
        "            neg_item = np.random.choice(list(self.all_movies))\n",
        "        return neg_item"
      ],
      "metadata": {
        "id": "dhC9QPZuybnp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. NCF Model\n",
        "class NCF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size=32, mlp_layers=[64, 32, 16]):\n",
        "        super(NCF, self).__init__()\n",
        "        self.user_embedding_gmf = nn.Embedding(num_users, embedding_size)\n",
        "        self.item_embedding_gmf = nn.Embedding(num_items, embedding_size)\n",
        "        self.user_embedding_mlp = nn.Embedding(num_users, embedding_size)\n",
        "        self.item_embedding_mlp = nn.Embedding(num_items, embedding_size)\n",
        "\n",
        "        mlp_modules = []\n",
        "        input_size = embedding_size * 2\n",
        "        for output_size in mlp_layers:\n",
        "            mlp_modules.append(nn.Linear(input_size, output_size))\n",
        "            mlp_modules.append(nn.ReLU())\n",
        "            input_size = output_size\n",
        "        self.mlp = nn.Sequential(*mlp_modules)\n",
        "\n",
        "        self.fusion_layer = nn.Linear(embedding_size + mlp_layers[-1], 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        user_emb_gmf = self.user_embedding_gmf(user)\n",
        "        item_emb_gmf = self.item_embedding_gmf(item)\n",
        "        gmf_output = user_emb_gmf * item_emb_gmf\n",
        "\n",
        "        user_emb_mlp = self.user_embedding_mlp(user)\n",
        "        item_emb_mlp = self.item_embedding_mlp(item)\n",
        "        mlp_input = torch.cat([user_emb_mlp, item_emb_mlp], dim=-1)\n",
        "        mlp_output = self.mlp(mlp_input)\n",
        "\n",
        "        fusion_input = torch.cat([gmf_output, mlp_output], dim=-1)\n",
        "        output = self.fusion_layer(fusion_input)\n",
        "        return self.sigmoid(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "s4H0tpg7ybtG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Recall@10\n",
        "def recall_at_k(model, test_loader, k=10):\n",
        "    model.eval()\n",
        "    recalls = []\n",
        "    with torch.no_grad():\n",
        "        for user, item, label in test_loader:\n",
        "            user, item, label = user.cuda(), item.cuda(), label.cuda()\n",
        "            pred = model(user, item)\n",
        "            _, indices = torch.topk(pred, k)\n",
        "            relevant = label[indices].sum()\n",
        "            total_relevant = label.sum()\n",
        "            if total_relevant > 0:\n",
        "                recalls.append(relevant / total_relevant)\n",
        "    return np.mean(recalls) if recalls else 0"
      ],
      "metadata": {
        "id": "7eXYD5-bybyT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    val_df = pd.read_csv('val.csv')\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "\n",
        "    #0-based indexing\n",
        "    for df in [train_df, val_df, test_df]:\n",
        "        df['userId'] = df['userId'] - 1\n",
        "        df['movie_idx'] = df['movie_idx'] - 1\n",
        "\n",
        "    # global sets for negative samplingg\n",
        "    all_movies = set(train_df['movie_idx'].unique()) | set(val_df['movie_idx'].unique()) | set(test_df['movie_idx'].unique())\n",
        "    user_item_set = set(zip(train_df['userId'].values, train_df['movie_idx'].values))\n",
        "\n",
        "    #datasets\n",
        "    train_dataset = MovieLensDataset(train_df, all_movies=all_movies, user_item_set=user_item_set)\n",
        "    val_dataset = MovieLensDataset(val_df, all_movies=all_movies, user_item_set=user_item_set)\n",
        "    test_dataset = MovieLensDataset(test_df, all_movies=all_movies, user_item_set=user_item_set)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=256)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=256)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=256)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "JXgPs8O-y5fU"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}